{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "#### To classify News articles as belonging to two categories - business or sports (binary classification)\n",
    "\n",
    "Any editing needs to be done only in the cells marked with \"Tune hyperparameters here\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Useful notebook shortcuts:\n",
    "\n",
    "Ctrl+Enter -> Run current cell\n",
    "\n",
    "Shift+Enter -> Run current cell and go to next cell\n",
    "\n",
    "Alt+Enter -> Run current cell and add new cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from model import *\n",
    "from feature import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path to the training data directory\n",
    "sports = readfiles('train/sports')\n",
    "business = readfiles('train/business')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare bag-of-words based features (for the whole data)\n",
    "\n",
    "#### To run this block: \n",
    "\n",
    "Complete the `preprocess` and `extract` function in the `BagOfWordsFeatureExtractor` class in `feature.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model and preprocess\n",
    "bow = BagOfWordsFeatureExtractor()\n",
    "bow.preprocess(business + sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract fetures and create a numpy array of features\n",
    "X_business_bow = bow.extract(business)\n",
    "X_sports_bow = bow.extract(sports)\n",
    "X_data_bow = np.concatenate((X_business_bow, X_sports_bow))\n",
    "\n",
    "# We know the correct labels, so create a numpy array for correct labels\n",
    "# Business -> 0, Sports -> 1\n",
    "Y_data_bow = np.concatenate((np.zeros(X_business_bow.shape[0]), np.ones(X_sports_bow.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and val sets\n",
    "\n",
    "General convention is to have a train/val split in the ratio of 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = X_data_bow.shape[0]\n",
    "num_val = np.int(num_train*0.3)\n",
    "\n",
    "# Permute the indices to randomly split data into train and val\n",
    "data_idxs = np.random.permutation(num_train)\n",
    "\n",
    "# Separate train data\n",
    "X_train_bow = X_data_bow[data_idxs[num_val:], :]\n",
    "Y_train_bow = Y_data_bow[data_idxs[num_val:]]\n",
    "\n",
    "# Separate val data\n",
    "X_val_bow = X_data_bow[data_idxs[:num_val], :]\n",
    "Y_val_bow = Y_data_bow[data_idxs[:num_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters here\n",
    "The model will get trained and the loss at various iterations will be printed. Try and reduce this loss through hyperparameter tuning, to get a better validation set accuracy in the next block. However, don't chase the number to a 1.0, as the focus is on implementation rather than winning a contest.\n",
    "\n",
    "### To run this block: \n",
    "Complete the following functions in `model.py` of class `LogisticRegression`\n",
    "1. `loss`\n",
    "2. `train`\n",
    "3. `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3               # Try changing the learning rate\n",
    "reg_const = 1.0         # Try changing the regularization constant\n",
    "add_bias = False        # Does adding bias help? Try changing between True and False\n",
    "num_iter = 10000        # Do not change\n",
    "\n",
    "model1 = LogisticRegression(add_bias) \n",
    "model1.train(X_train_bow, Y_train_bow, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Accuracy using Bag-of-words features\n",
    "\n",
    "We use the function `score` of class `LogisticRegression` in the file `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = model1.score(X_val_bow, Y_val_bow)\n",
    "print(\"Final Validation Set Accuracy - \", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for above model get recorded\n",
    "\n",
    "These hyperparameters will be your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_hyper('bow', add_bias, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tf-Idf based features (for the whole data)\n",
    "\n",
    "#### To run this block: \n",
    "Complete the `preprocess` and `extract` functions in the `TfIdfFeatureExtractor` class in `feature.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model and preprocess\n",
    "tfidf = TfIdfFeatureExtractor()\n",
    "tfidf.preprocess(business + sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract fetures and create a numpy array of features\n",
    "X_business_tfidf = tfidf.extract(business)\n",
    "X_sports_tfidf = tfidf.extract(sports)\n",
    "X_data_tfidf = np.concatenate((X_business_tfidf, X_sports_tfidf))\n",
    "\n",
    "# We know the correct labels, so create a numpy array for correct labels\n",
    "# Business -> 0, Sports -> 1\n",
    "Y_data_tfidf = np.concatenate((np.zeros(X_business_tfidf.shape[0]), np.ones(X_sports_tfidf.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and val sets\n",
    "\n",
    "General convention is to have a train/val split in the ratio of 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = X_business_tfidf.shape[0] + X_sports_tfidf.shape[0]\n",
    "num_val = np.int(num_train*0.3)\n",
    "X_data_tfidf = np.concatenate((X_business_tfidf, X_sports_tfidf))\n",
    "Y_data_tfidf = np.concatenate((np.zeros(X_business_tfidf.shape[0]), np.ones(X_sports_tfidf.shape[0])))\n",
    "\n",
    "# Data_idxs have been used from Bag of words section, so that we can fairly compare accuracies\n",
    "\n",
    "# Separate train data\n",
    "X_train_tfidf = X_data_tfidf[data_idxs[num_val:], :]\n",
    "Y_train_tfidf = Y_data_tfidf[data_idxs[num_val:]]\n",
    "\n",
    "# Separate val data\n",
    "X_val_tfidf = X_data_tfidf[data_idxs[:num_val], :]\n",
    "Y_val_tfidf = Y_data_tfidf[data_idxs[:num_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters here\n",
    "The model will get trained and the loss at various iterations will be printed. Try and reduce this loss through hyperparameter tuning, to get a better validation set accuracy in the next block. However, don't chase the number to a 1.0, as the focus is on implementation rather than winning a contest.\n",
    "\n",
    "You should have already implemented all the necessary functions to run this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3               # Try changing the learning rate\n",
    "reg_const = 1.0         # Try changing the regularization constant\n",
    "add_bias = False        # Does adding bias help? Try changing between True and False\n",
    "num_iter = 10000        # Do not change\n",
    "\n",
    "model2 = LogisticRegression(add_bias)\n",
    "model2.train(X_train_tfidf, Y_train_tfidf, lr, reg_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Accuracy using Bag-of-words features\n",
    "\n",
    "We use the function `score` of class `LogisticRegression` in the file `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = model2.score(X_val_tfidf, Y_val_tfidf)\n",
    "print(\"Final Validation Set Accuracy - \", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for above model get recorded\n",
    "\n",
    "These hyperparameters will be your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hyper('tf-idf', add_bias, lr, reg_const)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
